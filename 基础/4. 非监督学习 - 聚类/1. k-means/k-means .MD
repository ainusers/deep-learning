# k-means非监督学习算法


# k-means思想
非监督学习：事先并不清楚数据集的标记(结果)

首先会假设结果一共有k种，然后在散点图中随机选取k个位置的中心点，通过不断的循环计算数据点距离选取k种中心点
之后对当前k种中心点分别求取平均值，重新计算中心点，直至结果不会发生变化，模型训练结束


# K-means算法：
1.1 Clustering 中的经典算法，数据挖掘十大经典算法之一
1.2 算法接受参数 k ；然后将事先输入的n个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一
   聚类中的对象相似度较高；而不同聚类中的对象相似度较小。
1.3 算法思想：
   以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心
   的值，直至得到最好的聚类结果
1.4 算法描述：
（1）适当选择c个类的初始中心；
（2）在第k次迭代中，对任意一个样本，求其到c各中心的距离，将该样本归到距离最短的中心所在
    的类；
（3）利用均值等方法更新该类的中心值；
（4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，
    否则继续迭代


# k-means算法过程：
输入：k, data[n];
（1） 选择k个初始中心点，例如c[0]=data[0],…c[k-1]=data[k-1];
（2） 对于data[0]….data[n], 分别与c[0]…c[k-1]比较，假定与c[i]差值最少，就标记为i;
（3） 对于所有标记为i点，重新计算c[i]={ 所有标记为i的data[j]之和}/标记为i的个数；
（4） 重复(2)(3),直到所有c[i]值的变化小于给定阈值。


# k-means算法示例
![Image text](k-means算法示例.png)


# k-means优缺点
优点：速度快，简单
缺点：最终结果跟初始点选择相关，容易陷入局部最优，需直到k值