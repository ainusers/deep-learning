# 最邻近规则分类算法


# 综述
输入基于实例 (每一行训练集数据) 的学习


# 思想
将特征向量二维化，根据变量K(离当前节点最近的节点数目，一般取基数)，计算新的实例数据，距离所有节点的位置，采用少数服从多数的原则来绝对新实例数据的归属


# 算法步骤
为了判断未知实例的类别，以所有已知类别的实例作为参照
选择参数K
计算未知实例与所有已知实例的距离
选择最近K个已知实例
根据少数服从多数的投票法则(majority-voting)，让未知实例归类为K个最邻近样本中最多数的类别


# 计算距离的方法
![Image text](KNN_计算距离.jpg)
余弦值（cos）, 相关度 （correlation）, 曼哈顿距离 （Manhattan distance）


# 算法优点
简单
易于理解
容易实现
通过对K的选择可具备丢噪音数据的健壮性


# 算法缺点
![Image text](KNN_算法缺点.png)
需要大量空间储存所有已知实例
算法复杂度高（需要比较所有已知实例与要分类的实例）
当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，新的未知实例容易被归类为这个主导样本，
因为这类样本实例的数量过大，但这个新的未知实例实际并木接近目标样本


# 改进版本
考虑距离，根据距离加上权重
比如: 1/d (d: 距离）