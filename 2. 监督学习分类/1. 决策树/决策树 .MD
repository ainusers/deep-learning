# 决策树算法


1. 概念：
决策树：是一个类似于流程图的树结构：其中，每个内部结点表示在一个属性上的测试，每个分支代表一个属性输出，而每个树叶结点代表类或类分布。树的最顶层是根结点

信息熵：变量的不确定性越大，熵也就越大


# 思想
通过一定的计算规则，来计算某一个特征向量存放的节点位置


2. 选择特征向量作为决策树节点

2.1 ID3算法：
    信息获取量(Information Gain)：Gain(A) = Info(D) - Infor_A(D)


2.2 举个栗子
    ![Image text](决策树_ID3_计算规则.png)


2.3 其他算法
    C4.5 （gain ratio), CART(gini index), ID3 (Information Gain)
    都是贪心算法 (自上而下)，只是计算属性节点的规则不同


2.4. 决策树的优缺点
    优点：直观，便于理解，小规模数据集有效
    缺点：
        1. 处理连续变量不好
        2. 类别较多时，错误增加的比较快
        3. 可规模性一般