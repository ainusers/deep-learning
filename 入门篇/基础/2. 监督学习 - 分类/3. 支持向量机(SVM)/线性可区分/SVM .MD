# 支持向量机算法


# 机器学习的一般过程
训练数据集 > 提取特征向量 > 结合一定的算法(决策树/KNN) > 得到结果集


# 算法目标 (主要为了找出区分度最高(margin最大)的一条线，进而分类)
![Image text](SVM_算法图例.png)
寻找区分两类的超平面（hyper plane), 使边际(margin)最大


# 概念理解
支持向量：离超平面的那条线最近的两个最大和最小的阈值


# SVM算法过程
![Image text](SVM_算法过程.png)


# 线性可区分和线性不可区分
线性可区分：训练数据集可以找出超平面那条线
线性不可区分：训练数据集不可以找出超平面那条线


# SVM算法优点
1. 训练好的模型的算法复杂度是由支持向量的个数决定的，而不是由数据的维度决定的。所以SVM不太容易产生overfitting
2. SVM训练出来的模型完全依赖于支持向量(Support Vectors), 即使训练集里面所有非支持向量的点都被去除，重复训练过程，结果仍然会得到完全一样的模型
3. 一个SVM如果训练得出的支持向量个数比较小，SVM训练出的模型比较容易被泛化